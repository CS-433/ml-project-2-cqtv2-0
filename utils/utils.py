import numpy as np
import torch
import matplotlib.pyplot as plt
from skimage.transform import resize
from PIL import Image
import math 

def import_test(path='data/testing/test_set_images/'):
    """This function imports the test images from the path specified

    Args:
        path (str, optional): The path of the test images. Defaults to 'data/test_set_images/'.

    Returns:
        test_images: A numpy array of the test images.
    """
    test_images = []
    base_dir = 'test_'
    for i in range(1, 51):
        diri = base_dir + str(i)
        base_dir_i = path + diri + '/'
        img = np.array(Image.open(base_dir_i + diri + '.png')).astype('float32') / 255
        test_images.append(img)
    return np.array(test_images)

def show_images(tensor_x, tensor_y, nrow=2, ncol=4):
    """This function shows the images in tensor_x and tensor_y.

    Args:
        tensor_x (torch.tensor): The images we want to see.
        tensor_y (torch.tensor): The masks related to the images.
        nrow (int, optional): The number of rows of the figures. Defaults to 2.
        ncol (int, optional): the number of cols of the figures. Defaults to 4.
    """
    fig, axes = plt.subplots(nrow*2, ncol, figsize=(24, 24))
    tensor_x = np.transpose(tensor_x, (0, 2, 3, 1))
    tensor_y = tensor_y
    tensor_x = torch.clip(tensor_x, 0, 1)
    for i in range(nrow):
        for j in range(ncol):
            index = i * ncol + j
            img_x = tensor_x[index].cpu().numpy()
            img_y = tensor_y[index].cpu().numpy()
            axes[2*i, j].imshow(img_x, cmap='gray')
            axes[2*i, j].axis('off')
            
            axes[2*i + 1, j].imshow(img_y, cmap='gray')
            axes[2*i + 1, j].axis('off')
    
    plt.show()
    
def patch_extracting(input, x=584, y=384):
    """This function extracts the patches from the input image to get a better prediction.

    Args:
        input (np.array): The input image.
        x (int, optional): The size of the input image. Defaults to 584.
        y (int, optional): The target size of the patches of the input image. Defaults to 384.

    Returns:
        output: The patches extracted from the input image.
    """
    input_patches = [None, None, None, None]
    coords = [(0, y, 0, y), (0, y, x-y, x), (x-y, x, 0 , y), (x-y, x, x-y, x)]

    for i, (y1, y2, x1, x2) in enumerate(coords):
        input_patches[i] = input[:, y1:y2, x1:x2]
    return torch.from_numpy(np.array(input_patches)).float()


def patch_assembling(output_patches, x=384, y=584):
    """This function assembles the patches into a single image.

    Args:
        output_patches (np.array): The patches to be assembled.ยง
        x (int, optional): The size of the output image. Defaults to 384.
        y (int, optional): target size of the output image. Defaults to 584.
    Returns:
        output: The assembled image.
    """
    eL = int(y / 2)

    output = np.empty(shape=(output_patches.shape[1], y, y))
    
    out_cords = [(0, eL, 0, eL), (0, eL,y-eL, y), (y-eL, y, 0, eL), (y-eL, y, y-eL, y)]
    # Define the coordinates for the patches
    in_coords = [(0, eL, 0, eL), (0, eL, x-eL, x), (x-eL, x, 0, eL), (x-eL, x, x-eL, x)]
    # Assign the patches to the output array
    for i in range(len(out_cords)):
        o_x1, o_x2, o_y1, o_y2 = out_cords[i]
        x1, x2, y1, y2 = in_coords[i]
        output[:, o_x1:o_x2, o_y1:o_y2] = output_patches[i, :, x1:x2, y1:y2]
        
    return output[0, :, :]

def mask_to_submission(output, index):
    """This function creates the submission from the output. This function has been adapted from the original code from mask_to_submission.
    

    Args:
        output (np.array): The output of the model.
        index (int): The index of the image.

    Returns:
        mask_submission: The digits generated by the imag of the model.
    """
    mask_submission = []
    for i in range(0, output.shape[0], 16):
        for j in range(0, output.shape[1], 16):
            prediction = 0
            patch = output[j:j+16, i:i+16]
            if np.mean(patch > 0.2) > 0.25:
                prediction = 1
            mask_submission.append(["{:03d}_{}_{}".format(index, i, j), prediction])
    return mask_submission


def submission_creating(model, path_testing='data/testing/test_set_images/'):
    submit_outputs = []
    x_test = np.transpose(import_test(path_testing), (0, 3, 1, 2))
    model.eval()
    test_size = 608
    train_size = 400
    rsize = 384
    size = math.ceil(test_size*rsize/train_size)
    for index in range(1, 51):
        xi = x_test[index - 1]
        xi = resize(xi, (3, size, size))
        #Our model is trained on 384x384 images, so we need to resize the input image to 384x384
        patch_extracted = patch_extracting(xi)
        
        #We predict our patches
        output = (model(patch_extracted)[0]).detach().cpu().numpy()
        
        # We reassemble the patches
        output = patch_assembling(output)
        output = resize(output, (test_size, test_size))
        
        # We create the submission
        submit_output = mask_to_submission(output, index)
        submit_outputs.append(submit_output)

    submission = np.concatenate(submit_outputs, axis=0)
    submission = np.concatenate(([['id', 'prediction']], submission), axis=0)

    return submission
